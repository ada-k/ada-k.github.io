{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "[***Reddit***](https://www.reddit.com/) is an American social news aggregation, web content rating, and discussion website. Registered members submit content to the site such as links, text posts, and images, which are then voted up or down by other members.\n",
    "\n",
    "Thus it contains huge chunks of data whose analysis could yield so much insights especially towards understanding the behaviour of a particular community.\n",
    "\n",
    "It has subreddits indicating subtopics and each subreddit has moderators and members.\n",
    "\n",
    "[***Praw***](https://praw.readthedocs.io/en/latest/) is the Python reddit API wrapper.\n",
    "\n",
    "### Requirements\n",
    "1. Pandas - A software library written for the Python programming language for data manipulation and analysis.\n",
    "   Can be installed via ***pip, pipenv*** or ***conda***\n",
    "    * ` pip install pandas` \n",
    "    * ` pipenv install pandas` (in a virtual environment)\n",
    "    * ` conda install pandas` (in  conda environment)\n",
    "   \n",
    "2. Praw - The Python reddit API wrapper. Can be installed as follows:\n",
    "    * ` pip install praw` \n",
    "    * ` pipenv install praw` (in a virtual environment)\n",
    "   \n",
    "   \n",
    "3. Create an app from this [link](https://www.reddit.com/prefs/apps) to get the **cliend_id, client_secret** and **user_agent.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrapping data from the LiverpoolFC Subreddit.\n",
    "I love soccer, and a huge fan of Liverpool FC, so what better subreddit to scrap from than that.\n",
    "\n",
    "The first step is to create an instance of reddit after importing the 2 libraries:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "reddit = praw.Reddit(client_id = 'client_id', client_secret ='client_secret', user_agent='user_agent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then get the posts from the subreddit and specifiy the number of posts you're interested in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = reddit.subreddit('LiverpoolFC').hot(limit = 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Various attributes can be pulled from the post object. For instance:\n",
    "\n",
    "`Post Title, Name, Post URL, No. of Comments, Upvote Ratio (upvotes/downvotes), created at (timestamp), status(locked or not).`\n",
    "\n",
    "The following line of code pulls these attributes, creates a dataframe then saves the dataframe to a csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = ['title', 'name', 'url', 'score', 'locked', 'created', 'num of comment', 'upvote ratio']\n",
    "df = pd.DataFrame(([post.title, post.name, post.url, post.score, post.locked, post.created, post.num_comments, post.upvote_ratio]\n",
    "                   for post in posts), columns = c)\n",
    "df.to_csv('liverpool_subreddit.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To be continued to cover more features of praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
